{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1 Infraestrutura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando a biblioteca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib já está instalado.\n",
      "numpy já está instalado.\n",
      "pandas já está instalado.\n",
      "scipy já está instalado.\n",
      "seaborn já está instalado.\n",
      "scikit-learn não está instalado. Instalando...\n",
      "pyautogui já está instalado.\n",
      "distutils não está instalado. Instalando...\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['c:\\\\Users\\\\Caio Barroso\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe', '-m', 'pip', 'install', 'distutils']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 23\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;43m__import__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m já está instalado.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'distutils'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m não está instalado. Instalando...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m     \u001b[43minstall_package\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 18\u001b[0m, in \u001b[0;36minstall_package\u001b[1;34m(package)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minstall_package\u001b[39m(package):\n\u001b[1;32m---> 18\u001b[0m     \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-m\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minstall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Caio Barroso\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py:419\u001b[0m, in \u001b[0;36mcheck_call\u001b[1;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cmd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    418\u001b[0m         cmd \u001b[38;5;241m=\u001b[39m popenargs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 419\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, cmd)\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command '['c:\\\\Users\\\\Caio Barroso\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe', '-m', 'pip', 'install', 'distutils']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Lista de pacotes a serem instalados\n",
    "packages = [\n",
    "    \"matplotlib\",\n",
    "    \"numpy\",\n",
    "    \"pandas\",\n",
    "    \"scipy\",\n",
    "    \"seaborn\",\n",
    "    \"scikit-learn\",\n",
    "    \"pyautogui\"\n",
    "]\n",
    "\n",
    "# Função para instalar pacotes\n",
    "def install_package(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Verificar e instalar pacotes\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"{package} já está instalado.\")\n",
    "    except ImportError:\n",
    "        print(f\"{package} não está instalado. Instalando...\")\n",
    "        install_package(package)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'distutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pairwise_distances_argmin_min, r2_score, pairwise_distances\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler, MinMaxScaler\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn_extra\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMedoids\n",
      "File \u001b[1;32mc:\\Users\\Caio Barroso\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn_extra\\cluster\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_k_medoids\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMedoids, CLARA\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_commonnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m commonnn, CommonNNClustering\n\u001b[0;32m      4\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKMedoids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLARA\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommonNNClustering\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommonnn\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Caio Barroso\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn_extra\\cluster\\_commonnn.py:9\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"Density-Based Common-Nearest-Neighbors Clustering\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Author: Jan-Oliver Joswig <jan.joswig@fu-berlin.de>\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# License: BSD 3 clause\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LooseVersion\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'distutils'"
     ]
    }
   ],
   "source": [
    "# Importar os pacotes\n",
    "import sys\n",
    "import subprocess\n",
    "import pyautogui\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pkg_resources\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import AgglomerativeClustering, DBSCAN, KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min, r2_score, pairwise_distances\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn_extra.cluster import KMedoids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in c:\\users\\caio barroso\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (75.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\caio barroso\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (24.2)\n",
      "Collecting pip\n",
      "  Using cached pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\caio barroso\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (75.5.0)\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.45.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Using cached pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
      "Using cached wheel-0.45.0-py3-none-any.whl (72 kB)\n",
      "Installing collected packages: wheel, pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.2\n",
      "    Uninstalling pip-24.2:\n",
      "      Successfully uninstalled pip-24.2\n",
      "Successfully installed pip-24.3.1 wheel-0.45.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script wheel.exe is installed in 'c:\\Users\\Caio Barroso\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts pip.exe, pip3.13.exe and pip3.exe are installed in 'c:\\Users\\Caio Barroso\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip setuptools wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn-extra\n",
      "  Using cached scikit-learn-extra-0.3.0.tar.gz (818 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\caio barroso\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn-extra) (2.1.3)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\caio barroso\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn-extra) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=0.23.0 in c:\\users\\caio barroso\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn-extra) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\caio barroso\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn>=0.23.0->scikit-learn-extra) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\caio barroso\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn>=0.23.0->scikit-learn-extra) (3.5.0)\n",
      "Building wheels for collected packages: scikit-learn-extra\n",
      "  Building wheel for scikit-learn-extra (pyproject.toml): started\n",
      "  Building wheel for scikit-learn-extra (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for scikit-learn-extra: filename=scikit_learn_extra-0.3.0-cp313-cp313-win_amd64.whl size=401654 sha256=196edbc20635f004a2db9009bba9edf727b7f5eab3cf822138876e68ac46be5b\n",
      "  Stored in directory: c:\\users\\caio barroso\\appdata\\local\\pip\\cache\\wheels\\17\\4b\\b8\\6b6711681d0981b110c9cc91ad6d1ebd88adf1547e1da301fc\n",
      "Successfully built scikit-learn-extra\n",
      "Installing collected packages: scikit-learn-extra\n",
      "Successfully installed scikit-learn-extra-0.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn-extra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você está rodando em Python 3.9+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Versão do Python:\", sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você está usando um ambiente virtual: Virtualenv ou Anaconda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ambiente virtual ativo:\", sys.prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas as bibliotecas usadas nesse exercícios estão instaladas em um ambiente virtual específico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gere um arquivo de requerimentos (requirements.txt) com os pacotes necessários. É necessário se certificar que a versão do pacote está disponibilizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera o arquivo requirements.txt com os pacotes instalados\n",
    "with open(\"requirements.txt\", \"w\") as file:\n",
    "    subprocess.run([\"pip\", \"freeze\"], stdout=file)\n",
    "\n",
    "print(\"Arquivo requirements.txt gerado com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tire um printscreen do ambiente que será usado rodando em sua máquina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tira o print da tela e salva no arquivo screenshot.png\n",
    "screenshot = pyautogui.screenshot()\n",
    "screenshot.save(\"screenshot.png\")\n",
    "\n",
    "print(\"Screenshot salva como 'screenshot.png'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disponibilize os códigos gerados, assim como os artefatos acessórios (requirements.txt) e instruções em um repositório GIT público. (se isso não for feito, o diretório com esses arquivos deverá ser enviado compactado no moodle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2 Escolha de base de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baixe os dados disponibilizados na plataforma Kaggle sobre dados sócio-econômicos e de saúde que determinam o índice de desenvolvimento de um país. Esses dados estão disponibilizados através do link: https://www.kaggle.com/datasets/rohan0301/unsupervised-learning-on-country-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DATA\\Country-data.csv', encoding='latin-1', on_bad_lines='skip', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_traduzidas = [\n",
    "    'país', 'mortalidade_infantil', 'exportações', 'saúde', 'importações', \n",
    "    'renda', 'inflação', 'expectativa_de_vida', 'taxa_fertilidade', 'PIB'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualiza o DataFrame com os novos nomes de coluna:\n",
    "df.columns = colunas_traduzidas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantos países existem no dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver os valores únicos na coluna 'country'\n",
    "unique_countries = df['país'].unique()\n",
    "\n",
    "# Quantificar o número de países únicos\n",
    "num_countries = df['país'].nunique()\n",
    "print(f\"Quantidade de países no dataset: {num_countries}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostre através de gráficos a faixa dinâmica das variáveis que serão usadas nas tarefas de clusterização. Analise os resultados mostrados. O que deve ser feito com os dados antes da etapa de clusterização?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregar variaveis para plot\n",
    "variaveis_numericas = []\n",
    "\n",
    "for i in df.columns[0:11].to_list():\n",
    "    if df.dtypes[i] == \"int64\" or df.dtypes[i] == \"float64\":\n",
    "        variaveis_numericas.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurando o tamanho da figura\n",
    "plt.rcParams['figure.figsize'] = [20.00, 4.00]\n",
    "plt.rcParams['figure.autolayout'] = True\n",
    "\n",
    "# Criando os subplots para cada variável numérica\n",
    "f, axes = plt.subplots(1, len(variaveis_numericas))\n",
    "\n",
    "# Iterando sobre as variáveis numéricas e os eixos correspondentes\n",
    "for idx, i in enumerate(variaveis_numericas):\n",
    "    sns.boxplot(data=df, y=i, ax=axes[idx], color='#264653')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realize o pré-processamento adequado dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar listas para cada tipo de dado\n",
    "float_cols = []\n",
    "int_cols = []\n",
    "string_cols = []\n",
    "object_cols = []\n",
    "bool_cols = []\n",
    "datetime_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar sobre as colunas do DataFrame e verificar os tipos\n",
    "for col in df.columns:\n",
    "    if pd.api.types.is_float_dtype(df[col]):\n",
    "        float_cols.append(col)\n",
    "    elif pd.api.types.is_integer_dtype(df[col]):\n",
    "        int_cols.append(col)\n",
    "    elif pd.api.types.is_string_dtype(df[col]):\n",
    "        string_cols.append(col)\n",
    "    elif pd.api.types.is_object_dtype(df[col]):\n",
    "        object_cols.append(col)\n",
    "    elif pd.api.types.is_bool_dtype(df[col]):\n",
    "        bool_cols.append(col)\n",
    "    elif pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "        datetime_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir as listas\n",
    "print(\"Colunas float:\", float_cols)\n",
    "print(\"Colunas int:\", int_cols)\n",
    "print(\"Colunas string:\", string_cols)\n",
    "print(\"Colunas object:\", object_cols)\n",
    "print(\"Colunas bool:\", bool_cols)\n",
    "print(\"Colunas datetime:\", datetime_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[int_cols] = scaler.fit_transform(df[int_cols])\n",
    "df[float_cols] = scaler.fit_transform(df[float_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 3 Clusterização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar o agrupamento dos países em 3 grupos distintos. Para tal, use:\n",
    "K-Médias\n",
    "Clusterização Hierárquica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar as variáveis para o clustering (excluindo 'país' se estiver no DataFrame)\n",
    "variaveis_clusterizacao = df.drop(columns=['país'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para os resultados, do K-Médias:\n",
    "Interprete cada um dos clusters obtidos citando:\n",
    "Qual a distribuição das dimensões em cada grupo\n",
    "O país, de acordo com o algoritmo, melhor representa o seu agrupamento. Justifique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Definir o modelo com 3 clusters\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "df['cluster_kmeans'] = kmeans.fit_predict(variaveis_clusterizacao)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para os resultados da Clusterização Hierárquica, apresente o dendograma e interprete os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar a clusterização hierárquica\n",
    "linkage_matrix = linkage(variaveis_clusterizacao, method='complete')\n",
    "\n",
    "# Plotar o dendrograma\n",
    "plt.figure(figsize=(30, 20))\n",
    "dendro = dendrogram(linkage_matrix, labels=None, leaf_rotation=90, leaf_font_size=10)  # Remover os rótulos específicos dos países\n",
    "plt.title(\"Dendrograma da Clusterização Hierárquica\")\n",
    "plt.xlabel(\"Índices dos Nós\")\n",
    "plt.ylabel(\"Distância\")\n",
    "\n",
    "# Traçar uma linha vermelha pontilhada para a distância euclidiana de corte\n",
    "#distancia_corte = 15  # Ajuste este valor de corte conforme necessário\n",
    "#plt.axhline(y=distancia_corte, color='red', linestyle='--', label=f'Corte na Distância {distancia_corte}')\n",
    "\n",
    "# Adicionar rótulo do valor da distância em azul\n",
    "#plt.text(x=len(linkage_matrix) / 2, y=distancia_corte + 2, s=f\"Distância de Corte: {distancia_corte}\", color='blue', ha='center')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare os dois resultados, aponte as semelhanças e diferenças e interprete.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 04 Escolha de algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escreva em tópicos as etapas do algoritmo de K-médias até sua convergência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo de K-médias converge até encontrar os centróides que melhor descrevem os clusters encontrados (até o deslocamento entre as interações dos centróides ser mínimo). Lembrando que o centróide é o baricentro do cluster em questão e não representa, em via de regra, um dado existente na base. Refaça o algoritmo apresentado na questão 1 a fim de garantir que o cluster seja representado pelo dado mais próximo ao seu baricentro em todas as iterações do algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obs: nesse novo algoritmo, o dado escolhido será chamado medóide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo de K-médias é sensível a outliers nos dados. Explique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por que o algoritmo de DBScan é mais robusto à presença de outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim que terminar, salve o seu arquivo PDF e poste no Moodle. Utilize o seu nome para nomear o arquivo, identificando também a disciplina no seguinte formato: “nomedoaluno_nomedadisciplina_pd.PDF”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('fim')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
